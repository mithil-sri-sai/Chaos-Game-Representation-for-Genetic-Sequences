{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as NP\n",
    "import os \n",
    "import math\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as PLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(100,100)):\n",
    "    folders = [dir_path for dir_path in Path(container_path).iterdir()] \n",
    "    categories = [fo.name for fo in folders]\n",
    "    \n",
    "    descr = \"Alphacorona & Coronaviridae\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    \n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            img = skimage.io.imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "    flat_data = NP.array(flat_data)\n",
    "    target = NP.array(target)\n",
    "    images = NP.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_image_files(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\AI - Amrita\\\\Datasets\\\\CGR_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263,)\n",
      "(2,)\n",
      "(263, 40000)\n",
      "(263, 100, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "print(NP.shape(a.target))\n",
    "\n",
    "print(NP.shape(a.target_names))\n",
    "\n",
    "print(NP.shape(a.data))\n",
    "\n",
    "print(NP.shape(a.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, test_set_x_orig, tr_set_y, tes_set_y =  train_test_split(a.images, a.target, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 100, 100, 4)\n",
      "(66, 100, 100, 4)\n",
      "(197,)\n",
      "(66,)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(NP.shape(train_set_x_orig))\n",
    "\n",
    "print(NP.shape(test_set_x_orig))\n",
    "\n",
    "print(NP.shape(tr_set_y))\n",
    "\n",
    "print(NP.shape(tes_set_y))\n",
    "\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "print(num_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test sets and labels READY!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 197)\n",
      "(1, 197)\n",
      "(40000, 66)\n",
      "(1, 66)\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "print(NP.shape(train_set_x_flatten))\n",
    "\n",
    "train_set_y = train_set_y.reshape((1,len(tr_set_y)))\n",
    "print(NP.shape(train_set_y))\n",
    "\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "print(NP.shape(test_set_x_flatten))\n",
    "\n",
    "test_set_y = tes_set_y.reshape((1,len(tes_set_y)))\n",
    "print(NP.shape(test_set_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 197)\n",
      "(40000, 66)\n"
     ]
    }
   ],
   "source": [
    "print(NP.shape(train_set_x))\n",
    "print(NP.shape(test_set_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + NP.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \n",
    "    w = NP.zeros((dim, 1))\n",
    "    b = 0\n",
    "\n",
    "    assert (w.shape == (dim, 1))\n",
    "    assert (isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "\n",
    "    A = sigmoid(NP.dot(w.T, X) + b)  # compute activation\n",
    "    cost = (1. / m) * (-NP.dot(Y, NP.log(A).T) - NP.dot(1 - Y, NP.log(1 - A).T))  # compute cost\n",
    "\n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "\n",
    "    dw = 1. / m * NP.dot(X, (A - Y).T)\n",
    "    db = 1. / m * NP.sum(A - Y)\n",
    "\n",
    "    assert (dw.shape == w.shape)\n",
    "    assert (db.dtype == float)\n",
    "    cost = NP.squeeze(cost)\n",
    "    assert (cost.shape == ())\n",
    "\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "\n",
    "    return grads, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = NP.random.randint(1,5,size=(2*2*4,10))\n",
    "Y = NP.random.randint(0,2,size=(    1,10))\n",
    "\n",
    "w = NP.random.rand(2*2*4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads, cost = propagate(w, 0, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.563157474984694\n",
      "(16, 1)\n",
      "0.29999998016861606\n"
     ]
    }
   ],
   "source": [
    "print(cost)\n",
    "print(NP.shape(grads[\"dw\"]))\n",
    "print(grads[\"db\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    \n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Cost and gradient calculation\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        # update rule\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return params, grads, costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.563157\n",
      "Cost after iteration 100: 1.542720\n",
      "Cost after iteration 200: 0.361785\n",
      "Cost after iteration 300: 0.267294\n"
     ]
    }
   ],
   "source": [
    "param, grads_new, costs = optimize(w, 0, X, Y, 400, 0.005, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17648839058218646\n",
      "(16, 1)\n",
      "-0.010997205889646096\n",
      "(16, 1)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(param[\"b\"])\n",
    "print(NP.shape(param[\"w\"]))\n",
    "\n",
    "print(grads_new[\"db\"])\n",
    "print(NP.shape(grads_new[\"dw\"]))\n",
    "\n",
    "print(NP.shape(costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = NP.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "\n",
    "    A = sigmoid(NP.dot(w.T, X) + b)\n",
    "    print(\"\\n\", A)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "\n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "\n",
    "        for i in range(0, A.shape[1]):\n",
    "            \n",
    "            if A[0, i] > 0.5:\n",
    "                Y_prediction[0, i] = 1\n",
    "            else:\n",
    "                Y_prediction[0, i] = 0\n",
    "\n",
    "    assert (Y_prediction.shape == (1, m))\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(w,0,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=400, learning_rate=0.005, print_cost=False):\n",
    "    \n",
    "\n",
    "    # initialize parameters with zeros\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "\n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "\n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - NP.mean(NP.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - NP.mean(NP.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\": Y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.634010\n",
      "Cost after iteration 200: 0.592619\n",
      "Cost after iteration 300: 0.563402\n",
      "\n",
      " [[0.65551684 0.6570018  0.65560386 0.65743496 0.6569533  0.65726592\n",
      "  0.65727461 0.65678569 0.6578536  0.65507739 0.65699689 0.65666875\n",
      "  0.65618239 0.65629994 0.65696871 0.65551695 0.65618583 0.6569723\n",
      "  0.65630925 0.65519484 0.65544266 0.65614045 0.65639111 0.65497214\n",
      "  0.65614436 0.65711421 0.65537938 0.65700182 0.65499109 0.65531964\n",
      "  0.65657352 0.65716746 0.65579701 0.65639111 0.65603441 0.65716746\n",
      "  0.65697654 0.65715162 0.6578536  0.65554901 0.65583029 0.65713441\n",
      "  0.65572838 0.65613842 0.65609855 0.65624257 0.65622167 0.65710593\n",
      "  0.6562709  0.65641602 0.65706888 0.65618732 0.65555014 0.65624331\n",
      "  0.65768113 0.65542876 0.65709347 0.65696828 0.65678247 0.65554743\n",
      "  0.65694543 0.65715162 0.65677245 0.65693732 0.65698482 0.65483047]]\n",
      "\n",
      " [[0.65701095 0.65712571 0.65551105 0.65620431 0.65554727 0.6549647\n",
      "  0.65587581 0.65651235 0.65456802 0.65621053 0.65697052 0.65617804\n",
      "  0.65599215 0.6564701  0.65491475 0.65727461 0.65702261 0.65630238\n",
      "  0.65630925 0.6551878  0.65678569 0.6567911  0.65615039 0.65612795\n",
      "  0.65662626 0.65672948 0.65555002 0.6552205  0.65633137 0.65696554\n",
      "  0.65503735 0.65554171 0.65615859 0.65701095 0.65623132 0.65713975\n",
      "  0.65604541 0.65554788 0.65516371 0.65637872 0.65771028 0.65706416\n",
      "  0.65696736 0.6549693  0.65561523 0.65726592 0.65697095 0.65555005\n",
      "  0.65630519 0.657035   0.65570136 0.65630529 0.65710593 0.65556606\n",
      "  0.65496612 0.65629665 0.65602144 0.65616266 0.65694543 0.65624598\n",
      "  0.65609855 0.65618732 0.65658977 0.65618533 0.65700081 0.65701525\n",
      "  0.65616616 0.65554631 0.65657352 0.65598671 0.65615859 0.65657638\n",
      "  0.657206   0.65713441 0.65781479 0.65636522 0.65600183 0.65616921\n",
      "  0.65554921 0.65615039 0.65729517 0.65660774 0.65516263 0.65721223\n",
      "  0.65497194 0.65561189 0.65629665 0.65629994 0.65598934 0.65598671\n",
      "  0.65698368 0.65653664 0.65528171 0.65616829 0.65622516 0.65557792\n",
      "  0.65612851 0.65697068 0.65605138 0.65699961 0.65779374 0.65659521\n",
      "  0.65633137 0.65554167 0.6551636  0.65666875 0.65618573 0.65613955\n",
      "  0.65624273 0.65709347 0.65548106 0.65567972 0.65616026 0.65687025\n",
      "  0.65574065 0.65551806 0.65623132 0.65532624 0.65626803 0.65672948\n",
      "  0.65661223 0.65618573 0.65487966 0.65536009 0.65612851 0.65507739\n",
      "  0.65653589 0.65516362 0.65574083 0.65552913 0.65527599 0.65630246\n",
      "  0.65622215 0.65616921 0.6560495  0.6571167  0.65637872 0.65496852\n",
      "  0.65547962 0.65503688 0.65497216 0.65612795 0.65659521 0.65696865\n",
      "  0.65497088 0.6551631  0.65587581 0.65604953 0.65554975 0.65706416\n",
      "  0.65544853 0.65697057 0.65558354 0.65556604 0.65711277 0.65516236\n",
      "  0.65729517 0.65701095 0.65620171 0.65621053 0.65781479 0.65657638\n",
      "  0.65598934 0.65699961 0.6567911  0.65701095 0.65548898 0.65700081\n",
      "  0.65641602 0.65602144 0.65743496 0.65671815 0.65570504 0.65652339\n",
      "  0.65622215 0.65658977 0.65503707 0.65579567 0.65554937 0.65652429\n",
      "  0.65721223 0.65643343 0.65711869 0.657206   0.65570136 0.65613842\n",
      "  0.65652339 0.65696526 0.65559548 0.65614045 0.65620165 0.65512296\n",
      "  0.65555024 0.65713975 0.65556632 0.65604541 0.65616026]]\n",
      "train accuracy: 81.21827411167513 %\n",
      "test accuracy: 86.36363636363636 %\n"
     ]
    }
   ],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 400, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13636363636363635"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NP.mean(d[\"Y_prediction_test\"] - test_set_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
